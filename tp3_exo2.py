# -*- coding: utf-8 -*-
"""tp3_exo2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tCSmv6Hj1jdtHkgMfv0gobDo07urGEqo
"""

#initial intercept
p0=0.0
#initial slope
p1=0.0
# initializing the learning rate
a=0.01
#data size
m=3
#features
x=[1,2,4]
#target
y=[2,1,5]
print('intercept:{} , slope : {}   \nfeatures: {} \ntarget:{}'.format(p0,p1,x,y))

#Our model wich is a linear regression
def h(x):
  return p0+p1*x
print('h0 : {} '.format(h(x[0])))

#function that calculate new values of the intercept
def pa(x,y,p0,a,m):
  i=0
  sum=0
  f=0
  while i<m :
    dif = h(x[i])-y[i]
    sum =sum +dif
    i+=1
  fact=a / m
  f = p0 -  sum * fact 
  return f
print('the new intercept : {}'.format(pa(x,y,p0,a,m)))

#function that calculate the new values of the slope
def pb(x,y,p1,a,m):
  i=0
  sum=0
  while i<m :
    dif= h(x[i])-y[i]
    sum =sum + dif * x[i]
    i+=1
  return p1 - 0.01/3*sum
print('the new slope : {}'.format(pb(x,y,p1,a,m)))

#the function of the mean squared error aka MSE 
def err(x,y,m):
  i=1
  sum=0
  while(i<m):
    dif=h(x[i])-y[i]
    difq=dif*dif
    sum = sum + difq
    i+=1 
  return sum/(2*m)
print('the mean squared error : {}'.format(err(x,y,m)))

#this loop represent the gradient descent
i=0
while(i<60):
  p1=pb(x,y,p1,a,m)
  p0=pa(x,y,p0,a,m)
  e=err(x,y,m)
  print("iteration : {}  loss : {}".format(i,e))  
  i+=1